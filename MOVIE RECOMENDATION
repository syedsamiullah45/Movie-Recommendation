import pandas as pd
movies = pd.read_csv("movies_metadata.csv", usecols = [5,9,20])
movies_head()
def get_title(index):
    return movies[movies.index == index]["title"].values[0]
def get_index(title):
    return movies[movies.title == title]["index"].values[0]
movies['index'] = [i for i in range(0, len(movies))]
movies = movies.dropna()
!pip install sentence-transformers
from sentence_transformers import SentenceTransformer
bert = SentenceTransformer('bert-base-nli-mean-tokens')
 
Now we use the this model to get the vectors for the movies in our dataset.

sentence_embeddings = bert.encode(movies['overview'].tolist())
notOver = True
while(notOver):
    user_movie = input("Enter the movie for which you want recommendations: ")
# Generate Recommendations
    recommendations = sorted(list(enumerate(similarity[get_index(user_movie)])), key = lambda x:x[1], reverse = True)
    print("The top 3 recommendations for" + " " + user_movie + " " + "are: ")
    print(get_title(recommendations[1][0]), get_title(recommendations[2][0]), get_title(recommendations[3][0]), sep = "\n")
    decision = input("Press 1 to enter another movie, 0 to exit")
    if(int(decision) == 0):
        print("Bye")
        notOver = False


